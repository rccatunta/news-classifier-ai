{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Alda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Alda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re, string, unicodedata\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.data import load\n",
    "from nltk.stem import SnowballStemmer\n",
    "from string import punctuation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodico</th>\n",
       "      <th>titulo</th>\n",
       "      <th>cuerpo</th>\n",
       "      <th>fecha</th>\n",
       "      <th>categoria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La Razon</td>\n",
       "      <td>Gobierno refuerza plan ‘insertar’ 11 000 emple...</td>\n",
       "      <td>De cara  crisis  Gobierno reforzó  programas t...</td>\n",
       "      <td>1/7/2020</td>\n",
       "      <td>economia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La Razon</td>\n",
       "      <td>Revildescarta incremento pasaj  rias pide   ch...</td>\n",
       "      <td>Varios sindicatos dtransporte público  moviliz...</td>\n",
       "      <td>1/7/2020</td>\n",
       "      <td>sociedad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>La Razon</td>\n",
       "      <td>Murillo ordena buscar  cabecillas d‘grupo salv...</td>\n",
       "      <td>ministro Gobierno  rturo Murillo  nunció miérc...</td>\n",
       "      <td>1/7/2020</td>\n",
       "      <td>sociedad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>La Razon</td>\n",
       "      <td>Más 100 militar Colombia implicados  casos bus...</td>\n",
       "      <td>alto mando dejército Colombia reconoció miérco...</td>\n",
       "      <td>1/7/2020</td>\n",
       "      <td>mundial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La Razon</td>\n",
       "      <td>Las fiestas julias rán  pocas personas   verbe...</td>\n",
       "      <td>Las fiestas julias ño rán distintas evitar tag...</td>\n",
       "      <td>1/7/2020</td>\n",
       "      <td>sociedad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  periodico                                             titulo  \\\n",
       "0  La Razon  Gobierno refuerza plan ‘insertar’ 11 000 emple...   \n",
       "1  La Razon  Revildescarta incremento pasaj  rias pide   ch...   \n",
       "2  La Razon  Murillo ordena buscar  cabecillas d‘grupo salv...   \n",
       "3  La Razon  Más 100 militar Colombia implicados  casos bus...   \n",
       "4  La Razon  Las fiestas julias rán  pocas personas   verbe...   \n",
       "\n",
       "                                              cuerpo     fecha categoria  \n",
       "0  De cara  crisis  Gobierno reforzó  programas t...  1/7/2020  economia  \n",
       "1  Varios sindicatos dtransporte público  moviliz...  1/7/2020  sociedad  \n",
       "2  ministro Gobierno  rturo Murillo  nunció miérc...  1/7/2020  sociedad  \n",
       "3  alto mando dejército Colombia reconoció miérco...  1/7/2020   mundial  \n",
       "4  Las fiestas julias ño rán distintas evitar tag...  1/7/2020  sociedad  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data =pd.read_csv(r\"/Users/Alda/Desktop/prueba.csv\")\n",
    "text_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[')',\n",
       " '(',\n",
       " '“',\n",
       " '”',\n",
       " 'más',\n",
       " 'que',\n",
       " 'país',\n",
       " 'personas',\n",
       " 'pandemia',\n",
       " 'también',\n",
       " 'casos',\n",
       " 'años',\n",
       " '%',\n",
       " 'Bolivia',\n",
       " 'tán',\n",
       " 'gún',\n",
       " 'sí',\n",
       " 'demás',\n",
       " 'tra',\n",
       " '000',\n",
       " 'millon',\n",
       " 'social',\n",
       " 'coronavirus',\n",
       " 'salud',\n",
       " 'qui',\n",
       " 'tr',\n",
       " 'días',\n",
       " '?',\n",
       " 'Covid-19',\n",
       " 'red',\n",
       " 'Gobierno',\n",
       " 'tos',\n",
       " 'me',\n",
       " 'Paz',\n",
       " 'mayor',\n",
       " 'utoridad',\n",
       " '1',\n",
       " 'tado',\n",
       " 'Salud',\n",
       " 'trabajo',\n",
       " 'vida',\n",
       " 'vez',\n",
       " 'ctor',\n",
       " 'nacional',\n",
       " 'hacer',\n",
       " 'nte',\n",
       " 'to',\n",
       " 'día',\n",
       " 'había',\n",
       " 'os']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noticia = text_data.cuerpo.str.cat(sep=' ')\n",
    "#function to split text into word\n",
    "tokens = word_tokenize(noticia)\n",
    "vocabulary = set(tokens)\n",
    "print(len(vocabulary))\n",
    "frequency_dist = nltk.FreqDist(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop_words = set(stopwords.words('spanish'))\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.data import load\n",
    "from nltk.stem import SnowballStemmer\n",
    "from string import punctuation\n",
    "spanish_stopwords = stopwords.words('spanish')\n",
    "\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "\n",
    "non_words = list(punctuation)\n",
    "non_words.extend(['¿', '¡'])\n",
    "non_words.extend(map(str,range(10)))\n",
    "\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    # remove links from tweets\n",
    "    text = re.sub(r\"http\\S+\", \"https\", text)\n",
    "    # remove punctuation\n",
    "    text = ''.join([c for c in text if c not in non_words])\n",
    "    # remove repeated characters\n",
    "    text = re.sub(r'(.)\\1+', r'\\1\\1', text)\n",
    "    # tokenize\n",
    "    tokens =  word_tokenize(text)\n",
    "    # stem\n",
    "    try:\n",
    "        stems = stem_tokens(tokens, stemmer)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(text)\n",
    "        stems = ['']\n",
    "    return stems\n",
    "tokens = [w for w in tokens if not w in spanish_stopwords]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[')',\n",
       " '(',\n",
       " '“',\n",
       " '”',\n",
       " 'más',\n",
       " 'que',\n",
       " 'país',\n",
       " 'personas',\n",
       " 'pandemia',\n",
       " 'también',\n",
       " 'casos',\n",
       " 'años',\n",
       " '%',\n",
       " 'Bolivia',\n",
       " 'tán',\n",
       " 'gún',\n",
       " 'sí',\n",
       " 'demás',\n",
       " 'tra',\n",
       " '000',\n",
       " 'millon',\n",
       " 'social',\n",
       " 'coronavirus',\n",
       " 'salud',\n",
       " 'qui',\n",
       " 'tr',\n",
       " 'días',\n",
       " '?',\n",
       " 'Covid-19',\n",
       " 'red',\n",
       " 'Gobierno',\n",
       " 'tos',\n",
       " 'me',\n",
       " 'Paz',\n",
       " 'mayor',\n",
       " 'utoridad',\n",
       " '1',\n",
       " 'tado',\n",
       " 'Salud',\n",
       " 'trabajo',\n",
       " 'vida',\n",
       " 'vez',\n",
       " 'ctor',\n",
       " 'nacional',\n",
       " 'hacer',\n",
       " 'nte',\n",
       " 'to',\n",
       " 'día',\n",
       " 'había',\n",
       " 'os',\n",
       " 'tamos',\n",
       " 'tiempo',\n",
       " 'virus',\n",
       " 'ley',\n",
       " 'medidas',\n",
       " 'crisis',\n",
       " 'nuevo',\n",
       " 'gente',\n",
       " 'embargo',\n",
       " 'tanto',\n",
       " 'bi',\n",
       " 'mil',\n",
       " 'forma',\n",
       " 'cuarentena',\n",
       " 'caso',\n",
       " '2',\n",
       " 'tien',\n",
       " 'sido',\n",
       " '3',\n",
       " 'ño',\n",
       " 'lgunos',\n",
       " 'solo',\n",
       " 'tados',\n",
       " 'manera',\n",
       " 'fueron',\n",
       " 'tener',\n",
       " 'presidente',\n",
       " 'durante',\n",
       " 'mes',\n",
       " 'cuerdo',\n",
       " 'nueva',\n",
       " 'eleccion',\n",
       " 'situación',\n",
       " 'ctividad',\n",
       " 'momento',\n",
       " 'junio',\n",
       " 'debe',\n",
       " 'través',\n",
       " 'primer',\n",
       " 'julio',\n",
       " 'otras',\n",
       " 'cada',\n",
       " 'fermedad',\n",
       " 'rá',\n",
       " 'bolivianos',\n",
       " '10',\n",
       " 'cual',\n",
       " 'pued',\n",
       " 'después',\n",
       " 'datos']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noticia = text_data.cuerpo.str.cat(sep=' ')\n",
    "#function to split text into word\n",
    "tokens = word_tokenize(noticia)\n",
    "vocabulary = set(tokens)\n",
    "print(len(vocabulary))\n",
    "frequency_dist = nltk.FreqDist(tokens)\n",
    "sorted(frequency_dist,key=frequency_dist.__getitem__, reverse=True)[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se tiene que instalar:  python -m pip install wordcloud\n",
    "#from wordcloud import WordCloud\n",
    "#import matplotlib.pyplot as plt\n",
    "#wordcloud = WordCloud().generate_from_frequencies(frequency_dist)\n",
    "#plt.imshow(wordcloud)\n",
    "#plt.axis(\"off\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(text_data[\"cuerpo\"],text_data[\"categoria\"],test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(219, 13620) (25, 13620)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_vectors = vectorizer.fit_transform(X_train)\n",
    "test_vectors = vectorizer.transform(X_test)\n",
    "print(train_vectors.shape, test_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(train_vectors, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.52\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.metrics  import accuracy_score\n",
    "predicted = clf.predict(test_vectors)\n",
    "print(accuracy_score(Y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
